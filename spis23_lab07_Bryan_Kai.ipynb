{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK92UnSrqeOwA0GZim+cCX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucsd-cse-spis-2023/spis23-lab07-Bryan-Kai/blob/main/spis23_lab07_Bryan_Kai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHYQpsQAeY2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89edff75-21e2-4794-fa57-233aee83a25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like it like that You gotta believe me when\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "#training model\n",
        "def train(s):\n",
        "\n",
        "  wordDictionary = {}\n",
        "  words = s.split()\n",
        "  for i in range(len(words)-1):\n",
        "    currentWord = words[i]\n",
        "    nextWord = words[i+1]\n",
        "    if currentWord in wordDictionary:\n",
        "      wordDictionary[currentWord].append(nextWord)\n",
        "    else:\n",
        "      wordDictionary[currentWord] = [nextWord]\n",
        "\n",
        "  return wordDictionary\n",
        "\n",
        "train(\"Yeah baby I like it like that You gotta believe me when I tell you I said I like it like that\")\n",
        "\n",
        "model = train(\"Yeah baby I like it like that You gotta believe me when I tell you I said I like it like that\")\n",
        "\n",
        "def generate(model, first_word, num_words):\n",
        "\n",
        "  next_word = \" \"\n",
        "  text = \"\"\n",
        "\n",
        "  next_word = random.choice(model[first_word])\n",
        "  text += \" \" + next_word\n",
        "\n",
        "  for i in range(num_words - 2):\n",
        "    next_word = random.choice(model[next_word])\n",
        "    text += \" \" + next_word\n",
        "\n",
        "\n",
        "  print(first_word + text)\n",
        "\n",
        "generate(model, \"I\", 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# learning dictionary syntax from mentor\n",
        "dictionary = {}\n",
        "dictionary[\"Greeting\"] = [\"Hi\", \"Hello\", \"Hey\"]\n",
        "print(dictionary)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1kDuNq8kBgM",
        "outputId": "00351276-bdeb-49fd-ac3f-9bd685f95bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Greeting': ['Hi', 'Hello', 'Hey']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''dictionary[\"Greeting\"].append(\"Howdy\")'''"
      ],
      "metadata": {
        "id": "WZxyxyZzkN_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''print(dictionary[\"Greeting\"])'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYTVCkK0ktO0",
        "outputId": "f7cea92f-9518-424c-80ea-24a8e2480281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', 'Hello', 'Hey', 'Howdy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''print(\"wassup\" in dictionary)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoq-wqz3kwZ7",
        "outputId": "d4a82444-5bd5-4091-de5b-ab30407b9253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.classify.util import accuracy\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "def format_sentence(sent):\n",
        "\n",
        "    tokens = nltk.word_tokenize(sent)\n",
        "\n",
        "    return({word: True for word in tokens})\n",
        "\n",
        "\n",
        "\n",
        "def get_reviews(data, rating):\n",
        "\n",
        "    rows = data['Rating']==rating\n",
        "\n",
        "    return list(data.loc[rows, 'Review'])\n",
        "\n",
        "\n",
        "\n",
        "def split_train_test(data, train_prop):\n",
        "  data = [\"A\", \"B\", \"C\", \"D\"]\n",
        "  new_data = data[:0.25]\n",
        "    ''' input: A list of data, train_prop is a number between 0 and 1\n",
        "\n",
        "              specifying the proportion of data in the training set.\n",
        "\n",
        "        output: A tuple of two lists, (training, testing)\n",
        "\n",
        "    '''\n",
        "\n",
        "    # TODO: You will write this function, and change the return value\n",
        "\n",
        "    return ([], [])\n",
        "\n",
        "\n",
        "\n",
        "def format_for_classifier(data_list, label):\n",
        "\n",
        "    ''' input: A list of documents represented as text strings\n",
        "\n",
        "               The label of the text strings.\n",
        "\n",
        "        output: a list with one element for each doc in data_list,\n",
        "\n",
        "                where each entry is a list of two elements:\n",
        "\n",
        "                [format_sentence(doc), label]\n",
        "\n",
        "    '''\n",
        "\n",
        "    # TODO: Write this function, change the return value\n",
        "\n",
        "    return []\n",
        "\n",
        "\n",
        "\n",
        "def classify_reviews():\n",
        "\n",
        "    ''' Perform sentiment classification on movie reviews '''\n",
        "\n",
        "    # Read the data from the file\n",
        "\n",
        "    data = pd.read_csv(\"movie_reviews.csv\")\n",
        "\n",
        "\n",
        "\n",
        "    # get the text of the positive and negative reviews only.\n",
        "\n",
        "    # positive and negative will be lists of strings\n",
        "\n",
        "    # For now we use only very positive and very negative reviews.\n",
        "\n",
        "    positive = get_reviews(data, 4)\n",
        "\n",
        "    negative = get_reviews(data, 0)\n",
        "\n",
        "\n",
        "\n",
        "    # Split each data set into training and testing sets.\n",
        "\n",
        "    # You have to write the function split_train_test\n",
        "\n",
        "    (pos_train_text, pos_test_text) = split_train_test(positive, 0.8)\n",
        "\n",
        "    (neg_train_text, neg_test_text) = split_train_test(negative, 0.8)\n",
        "\n",
        "\n",
        "\n",
        "    # Format the data to be passed to the classifier.\n",
        "\n",
        "    # You have to write the format_for_classifier function\n",
        "\n",
        "    pos_train = format_for_classifier(pos_train_text, 'pos')\n",
        "\n",
        "    neg_train = format_for_classifier(neg_train_text, 'neg')\n",
        "\n",
        "\n",
        "\n",
        "    # Create the training set by appending the pos and neg training examples\n",
        "\n",
        "    training = pos_train + neg_train\n",
        "\n",
        "\n",
        "\n",
        "    # Format the testing data for use with the classifier\n",
        "\n",
        "    pos_test = format_for_classifier(pos_test_text, 'pos')\n",
        "\n",
        "    neg_test = format_for_classifier(neg_test_text, 'neg')\n",
        "\n",
        "    # Create the test set\n",
        "\n",
        "    test = pos_test + neg_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Train a Naive Bayes Classifier\n",
        "\n",
        "    # Uncomment the next line once the code above is working\n",
        "\n",
        "    #classifier = NaiveBayesClassifier.train(training)\n",
        "\n",
        "\n",
        "\n",
        "    # Uncomment the next two lines once everything above is working\n",
        "\n",
        "    #print(\"Accuracy of the classifier is: \" + str(accuracy(classifier, test)))\n",
        "\n",
        "    #classifier.show_most_informative_features()\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Calculate and print the accuracy on the positive and negative\n",
        "\n",
        "    # documents separately\n",
        "\n",
        "    # You will want to use the function classifier.classify, which takes\n",
        "\n",
        "    # a document formatted for the classifier and returns the classification\n",
        "\n",
        "    # of that document (\"pos\" or \"neg\").  For example:\n",
        "\n",
        "    # classifier.classify(format_sentence(\"I love this movie. It was great!\"))\n",
        "\n",
        "    # will (hopefully!) return \"pos\"\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Print the misclassified examples"
      ],
      "metadata": {
        "id": "eWz7pkj5OBjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"A\", \"B\", \"C\", \"D\"]\n",
        "new_data1 = data[:int(len(data)*0.25)]\n",
        "new_data2 = data[int(len(data)*0.25):]\n",
        "print(new_data1, new_data2)"
      ],
      "metadata": {
        "id": "VVUqGPkSGbsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"A\", \"B\", \"C\", \"D\"]\n",
        "num = 0.25\n",
        "return (data[:int(len(data)*0.25)], data[int(len(data)*0.25):])"
      ],
      "metadata": {
        "id": "VNnTc9bDGen4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}